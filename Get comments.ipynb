{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML, display\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('all_heads_links_nodups.txt', 'r', encoding='utf-8') as f:\n",
    "    all_heads_links = f.read().split('\\n')\n",
    "info_all = []\n",
    "for line in all_heads_links:\n",
    "    line = line.split('\\t')\n",
    "    info_all.append((line[0], line[1]))\n",
    "\n",
    "with open('polemic_headlines_by_themes.txt', 'r', encoding='utf-8') as f1:\n",
    "    topics = f1.read().split('\\n\\n')\n",
    "cluster_heads = []\n",
    "for group in topics:\n",
    "    cluster_heads.append(group.split('\\n'))\n",
    "\n",
    "to_get_comments = []\n",
    "for cluster in cluster_heads:\n",
    "    clstr_arr = []\n",
    "    for headline in cluster[1:]:\n",
    "        for head in info_all:\n",
    "            if headline == head[0]:\n",
    "                clstr_arr.append(head[1])\n",
    "    clstr_arr = list(set(clstr_arr))\n",
    "    to_get_comments.append((cluster[0], clstr_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6',\n",
       " ['https://ria.ru/world/20170504/1493626174.html',\n",
       "  'https://ria.ru/world/20170502/1493537580.html',\n",
       "  'https://ria.ru/world/20170206/1487252689.html',\n",
       "  'https://ria.ru/world/20170302/1489156170.html',\n",
       "  'https://ria.ru/world/20170405/1491538862.html',\n",
       "  'https://ria.ru/world/20170423/1492892954.html',\n",
       "  'https://ria.ru/politics/20170518/1494587195.html',\n",
       "  'https://ria.ru/world/20170507/1493859279.html',\n",
       "  'https://ria.ru/world/20170506/1493812162.html',\n",
       "  'https://ria.ru/world/20170501/1493432663.html',\n",
       "  'https://ria.ru/world/20170420/1492698853.html',\n",
       "  'https://ria.ru/world/20170508/1493893247.html',\n",
       "  'https://ria.ru/world/20170612/1496326049.html',\n",
       "  'https://ria.ru/world/20170316/1490150792.html',\n",
       "  'https://ria.ru/world/20170305/1489320492.html',\n",
       "  'https://ria.ru/world/20170423/1492915883.html',\n",
       "  'https://ria.ru/world/20170423/1492921318.html',\n",
       "  'https://ria.ru/world/20170428/1493313037.html'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_get_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing  6  cluster\n",
      "Now processing  7  cluster\n",
      "Now processing  12  cluster\n",
      "Now processing  16  cluster\n",
      "Now processing  20  cluster\n",
      "Now processing  21  cluster\n",
      "Now processing  24  cluster\n",
      "Now processing  30  cluster\n",
      "Now processing  33  cluster\n",
      "Now processing  34  cluster\n",
      "Duration: 0:06:25.877341\n"
     ]
    }
   ],
   "source": [
    "def get_data_id(comment_sect, data_id):\n",
    "    '''\n",
    "    data_id последнего комента верхнего уровня с текущей страницы для ссылки на следующую страницу\n",
    "    '''      \n",
    "    for bla in comment_sect:\n",
    "        try:\n",
    "            data_id = bla['data-ts']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return data_id\n",
    "\n",
    "def get_text(text, comment):\n",
    "    '''\n",
    "    Достать текст из тега\n",
    "    '''\n",
    "    for sect in text:\n",
    "        comment += str(sect)\n",
    "    comment = re.sub('<br/>', '', comment)\n",
    "    return comment\n",
    "\n",
    "def get_author(comment_sect, users):\n",
    "    '''\n",
    "    собрать комментировавших и отвечавших юзеров для каждого коммента и сколько раз каждый из них писал\n",
    "    '''\n",
    "    for author in comment_sect.findAll('a', {'class':'b-comments__item-author'}):\n",
    "        if author:\n",
    "            for each in author:\n",
    "                for nick in each:\n",
    "                    users[nick] += 1\n",
    "\n",
    "def get_comment_text(comment_sect, each_comment):\n",
    "    '''\n",
    "    сбор непосредственно комментов и их дат\n",
    "    '''\n",
    "    for comment_itself in comment_sect.find('div', {'class':'b-comments__item m-first-level'}):\n",
    "        if comment_itself:\n",
    "            comment = ''\n",
    "            date = comment_itself.find('div', {'class':'b-comments__item-date'})\n",
    "            if date:\n",
    "                date = date['datetime']\n",
    "                text = comment_itself.find('div', {'class':'b-comments__item-text'})\n",
    "                if text:\n",
    "                    each_comment.append(get_text(text, comment))\n",
    "    return date\n",
    "\n",
    "def get_replies(comment_sect, each_comment, users):\n",
    "    '''\n",
    "    сбор ответов на комменты\n",
    "    '''\n",
    "    reply = ''\n",
    "    reply_date = 0\n",
    "    for reply_itself in comment_sect.find('div', {'class':'b-comments__list-answer'}):#'b-comments__list-items'\n",
    "        if reply_itself:\n",
    "            for for_reply_dates in reply_itself.findAll('div', {'class':'b-comments__item'}):\n",
    "                if for_reply_dates:\n",
    "                    reply_date = for_reply_dates['data-ts']\n",
    "            text = reply_itself.findAll('div', {'class':'b-comments__item-text'})\n",
    "            #date последнего ответа на коммент\n",
    "            if text:                \n",
    "                for sect in text:\n",
    "                    each_comment.append(get_text(sect, reply))\n",
    "                        \n",
    "            next_reply_page = comment_sect.find('div', {'class':'b-comments__list-answer-load'})\n",
    "            if next_reply_page:\n",
    "                try:\n",
    "                    next_reply_page['style']\n",
    "                except KeyError:\n",
    "                    next_replies(next_reply_page, users, reply_date, each_comment)\n",
    "\n",
    "def next_replies(next_reply_page, users, reply_date, each_comment):\n",
    "    '''\n",
    "    перейти на страницу со всеми ответами, выкачать их и логины юзеров\n",
    "    '''\n",
    "    next_reply = ''\n",
    "    parent_id = next_reply_page['data-parent_id']\n",
    "    reply_link = 'https://ria.ru/services/comments/get_list/?article_id='+article_id+'&parent_id='+parent_id+'&date='+str(reply_date)\n",
    "    req_reply = requests.get(reply_link)\n",
    "    soup_reply = BeautifulSoup(req_reply.text, 'lxml')\n",
    "    \n",
    "    for by_reply in soup_reply.findAll('div', {'class':'b-comments__item'}):\n",
    "        if by_reply:\n",
    "            reply_date = by_reply['data-ts']\n",
    "            get_author(by_reply, users)\n",
    "            text = by_reply.findAll('div', {'class':'b-comments__item-text'})\n",
    "            if text:\n",
    "                for sect in text:\n",
    "                    each_comment.append(get_text(sect, next_reply))\n",
    "            next_reply_page = by_reply.find('div', {'class':'b-comments__list-answer-load'})\n",
    "            if next_reply_page:\n",
    "                print('Noooooooooooooo')\n",
    "                next_replies(next_reply_page, users, reply_date)\n",
    "    return next_reply_page, users\n",
    "        \n",
    "def main_walker(comments_link, article_id, headline_comments_replies):\n",
    "    '''\n",
    "    Функция получает на вход ссылку, и собирает в массив кортежи из комметария, \n",
    "    ответов на него и словаря с пользователями и количеством комментов/ответов от них\n",
    "    '''\n",
    "    req = requests.get(comments_link)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    data_id = 0\n",
    "    for comment_sect in soup.findAll('div', {'class':'b-comments__list-tree'}):\n",
    "        data_id = get_data_id(comment_sect, data_id) #data_id последнего комента верхнего уровня с текущей страницы для ссылки на следующую страницу\n",
    "        date = ''\n",
    "        each_comment = []\n",
    "        date = get_comment_text(comment_sect, each_comment) #сбор непосредственно комментов и их дат\n",
    "        users = defaultdict(int)\n",
    "        get_author(comment_sect, users)\n",
    "        get_replies(comment_sect, each_comment, users)\n",
    "        headline_comments_replies.append((date, list(set(each_comment)), users))\n",
    "        \n",
    "    next_p = soup.find('div', {'class':'b-comments__list-answer'})\n",
    "    if next_p:\n",
    "        comments_link = 'https://ria.ru/services/comments/get_list/?article_id='+article_id+'&sort=desc&date='+data_id\n",
    "        main_walker(comments_link, article_id, headline_comments_replies)\n",
    "\n",
    "start_time = datetime.now()\n",
    "trial = ['https://ria.ru/world/20171010/1506569366.html']\n",
    "polemic_comments = []\n",
    "for cortege in to_get_comments:\n",
    "    polemic_cortege = []\n",
    "    print('Now processing cluster №\\t', cortege[0])\n",
    "    for headline in cortege[1]:\n",
    "        link = cortege[1][headline]\n",
    "        article_id = link[-15:-5] \n",
    "        comments_link = 'https://ria.ru/services/comments/get_list/?article_id='+article_id+'&sort=desc&add_class=m-main-list'\n",
    "        headline_comments_replies = []\n",
    "        main_walker(comments_link, article_id, headline_comments_replies)\n",
    "        polemic_cortege.append((headline, cortege[1][headline], headline_comments_replies))\n",
    "    polemic_comments.append((cortege[0], polemic_cortege))\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "with open('polemic_comments.pkl', 'wb') as fp:\n",
    "    pickle.dump(polemic_comments, fp)\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
