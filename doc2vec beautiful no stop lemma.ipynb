{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import re\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "import pymorphy2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "stw = set(txt.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:12:26.004794\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def preprocess(str):\n",
    "    # remove links\n",
    "    # str = re.sub(r'http(s)?:\\/\\/\\S*? ', \"\", str)\n",
    "    str = re.sub(r'[^а-яёА-ЯЁ ]+', '', str)\n",
    "\n",
    "    return str\n",
    "\n",
    "class Documents(object):\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            yield TaggedDocument(words = doc, tags = [i])\n",
    "\n",
    "file = 'train_headlines.txt'\n",
    "\n",
    "\n",
    "corpus = open(file, \"r\", encoding='utf-8')\n",
    "lines = corpus.read().lower().split(\"\\n\")\n",
    "count = len(lines)\n",
    "preprocessed = []\n",
    "\n",
    "duplicate_dict = {}\n",
    "\n",
    "for t in lines:\n",
    "    if t not in duplicate_dict:\n",
    "        duplicate_dict[t] = True\n",
    "        #t = preprocess(t)\n",
    "        fixedNoStop = []\n",
    "        fixed =''.join([x if x.isalnum() or x.isspace() else \" \" for x in t ]).split()\n",
    "        for fix in fixed:\n",
    "            if fix not in stw:\n",
    "                fix = morph.parse(fix)[0].normal_form\n",
    "                fixedNoStop.append(fix)\n",
    "        preprocessed.append(fixedNoStop)\n",
    "\n",
    "documents = Documents(preprocessed)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:32:27,402 : INFO : collecting all words and their counts\n",
      "2018-05-06 21:32:27,406 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-05-06 21:32:27,612 : INFO : PROGRESS: at example #10000, processed 70313 words (347365/s), 9299 word types, 10000 tags\n",
      "2018-05-06 21:32:27,757 : INFO : PROGRESS: at example #20000, processed 140114 words (490024/s), 12398 word types, 20000 tags\n",
      "2018-05-06 21:32:27,916 : INFO : PROGRESS: at example #30000, processed 209942 words (445929/s), 14741 word types, 30000 tags\n",
      "2018-05-06 21:32:28,046 : INFO : PROGRESS: at example #40000, processed 279980 words (549897/s), 16598 word types, 40000 tags\n",
      "2018-05-06 21:32:28,226 : INFO : PROGRESS: at example #50000, processed 349973 words (393458/s), 18080 word types, 50000 tags\n",
      "2018-05-06 21:32:28,399 : INFO : PROGRESS: at example #60000, processed 419910 words (411510/s), 19352 word types, 60000 tags\n",
      "2018-05-06 21:32:28,559 : INFO : PROGRESS: at example #70000, processed 489711 words (450349/s), 20519 word types, 70000 tags\n",
      "2018-05-06 21:32:28,752 : INFO : PROGRESS: at example #80000, processed 560052 words (369381/s), 22517 word types, 80000 tags\n",
      "2018-05-06 21:32:28,970 : INFO : PROGRESS: at example #90000, processed 630908 words (328484/s), 24248 word types, 90000 tags\n",
      "2018-05-06 21:32:29,151 : INFO : PROGRESS: at example #100000, processed 700506 words (392255/s), 25390 word types, 100000 tags\n",
      "2018-05-06 21:32:29,337 : INFO : PROGRESS: at example #110000, processed 768258 words (371244/s), 26945 word types, 110000 tags\n",
      "2018-05-06 21:32:29,488 : INFO : PROGRESS: at example #120000, processed 835970 words (457885/s), 27854 word types, 120000 tags\n",
      "2018-05-06 21:32:29,646 : INFO : PROGRESS: at example #130000, processed 903995 words (435785/s), 29127 word types, 130000 tags\n",
      "2018-05-06 21:32:29,809 : INFO : PROGRESS: at example #140000, processed 972667 words (428507/s), 30680 word types, 140000 tags\n",
      "2018-05-06 21:32:29,923 : INFO : collected 31479 word types and 146487 unique tags from a corpus of 146487 examples and 1016989 words\n",
      "2018-05-06 21:32:29,926 : INFO : Loading a fresh vocabulary\n",
      "2018-05-06 21:32:30,027 : INFO : min_count=6 retains 11122 unique words (35% of original 31479, drops 20357)\n",
      "2018-05-06 21:32:30,030 : INFO : min_count=6 leaves 979143 word corpus (96% of original 1016989, drops 37846)\n",
      "2018-05-06 21:32:30,174 : INFO : deleting the raw counts dictionary of 31479 items\n",
      "2018-05-06 21:32:30,178 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2018-05-06 21:32:30,181 : INFO : downsampling leaves estimated 941148 word corpus (96.1% of prior 979143)\n",
      "2018-05-06 21:32:30,189 : INFO : estimated required memory for 11122 words and 80 dimensions: 59554920 bytes\n",
      "2018-05-06 21:32:30,323 : INFO : resetting layer weights\n",
      "2018-05-06 21:32:38,123 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:32:39,268 : INFO : PROGRESS: at 0.95% examples, 9246 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:40,978 : INFO : PROGRESS: at 8.70% examples, 33649 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:42,744 : INFO : PROGRESS: at 16.48% examples, 39243 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:44,448 : INFO : PROGRESS: at 24.24% examples, 42134 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:45,480 : INFO : PROGRESS: at 30.06% examples, 44924 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:32:47,171 : INFO : PROGRESS: at 35.88% examples, 43597 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:48,315 : INFO : PROGRESS: at 39.75% examples, 42874 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:49,430 : INFO : PROGRESS: at 46.56% examples, 45250 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:50,910 : INFO : PROGRESS: at 51.41% examples, 44180 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:51,979 : INFO : PROGRESS: at 58.13% examples, 46147 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:53,034 : INFO : PROGRESS: at 61.95% examples, 45728 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:54,503 : INFO : PROGRESS: at 66.83% examples, 44831 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:55,737 : INFO : PROGRESS: at 72.82% examples, 45386 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:56,849 : INFO : PROGRESS: at 77.83% examples, 45622 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:58,287 : INFO : PROGRESS: at 82.85% examples, 45099 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:32:59,359 : INFO : PROGRESS: at 87.83% examples, 45345 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:00,515 : INFO : PROGRESS: at 93.76% examples, 45839 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-06 21:33:01,172 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:33:01,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:33:01,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:33:01,515 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:33:01,515 : INFO : training on 1016989 raw words (1087530 effective words) took 23.4s, 46491 effective words/s\n",
      "2018-05-06 21:33:01,531 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:33:01,531 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:33:01,547 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:33:01,562 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:33:02,075 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:33:02,497 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:33:02,502 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:33:03,651 : INFO : PROGRESS: at 0.95% examples, 9252 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:04,713 : INFO : PROGRESS: at 4.82% examples, 24206 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:05,889 : INFO : PROGRESS: at 8.70% examples, 28433 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:07,093 : INFO : PROGRESS: at 12.58% examples, 30295 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:08,139 : INFO : PROGRESS: at 17.45% examples, 34120 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:09,206 : INFO : PROGRESS: at 23.27% examples, 38229 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:10,877 : INFO : PROGRESS: at 28.12% examples, 36947 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:11,927 : INFO : PROGRESS: at 33.94% examples, 39630 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:13,001 : INFO : PROGRESS: at 38.79% examples, 40646 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:14,163 : INFO : PROGRESS: at 42.67% examples, 40249 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:15,488 : INFO : PROGRESS: at 46.56% examples, 39426 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:16,938 : INFO : PROGRESS: at 51.41% examples, 39151 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:18,008 : INFO : PROGRESS: at 56.21% examples, 39887 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:19,075 : INFO : PROGRESS: at 61.95% examples, 41166 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:20,396 : INFO : PROGRESS: at 66.83% examples, 41062 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:21,628 : INFO : PROGRESS: at 71.82% examples, 41258 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:22,729 : INFO : PROGRESS: at 77.83% examples, 42267 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:23,845 : INFO : PROGRESS: at 81.84% examples, 42108 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:25,156 : INFO : PROGRESS: at 86.84% examples, 42068 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:26,228 : INFO : PROGRESS: at 91.79% examples, 42409 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:27,143 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:33:27,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:33:27,359 : INFO : PROGRESS: at 98.72% examples, 43473 words/s, in_qsize 1, out_qsize 1\n",
      "2018-05-06 21:33:27,362 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:33:27,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:33:27,394 : INFO : training on 1016989 raw words (1087560 effective words) took 24.9s, 43721 effective words/s\n",
      "2018-05-06 21:33:27,398 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:33:27,406 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:33:27,409 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:33:27,413 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:33:27,829 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:33:28,135 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:33:28,138 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:33:29,188 : INFO : PROGRESS: at 1.91% examples, 20543 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:30,194 : INFO : PROGRESS: at 7.73% examples, 41859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:31,818 : INFO : PROGRESS: at 12.59% examples, 37853 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:32,978 : INFO : PROGRESS: at 16.48% examples, 37590 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:34,029 : INFO : PROGRESS: at 21.33% examples, 39932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:35,611 : INFO : PROGRESS: at 28.12% examples, 41462 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:36,664 : INFO : PROGRESS: at 33.94% examples, 43859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:38,188 : INFO : PROGRESS: at 39.76% examples, 43563 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:39,224 : INFO : PROGRESS: at 46.56% examples, 46214 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:40,602 : INFO : PROGRESS: at 51.41% examples, 45370 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:41,705 : INFO : PROGRESS: at 55.25% examples, 44824 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:42,877 : INFO : PROGRESS: at 60.99% examples, 45587 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:33:44,358 : INFO : PROGRESS: at 66.83% examples, 45322 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:45,411 : INFO : PROGRESS: at 71.83% examples, 45707 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:46,501 : INFO : PROGRESS: at 76.83% examples, 45979 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:48,129 : INFO : PROGRESS: at 82.85% examples, 45523 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:49,135 : INFO : PROGRESS: at 86.84% examples, 45401 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:50,274 : INFO : PROGRESS: at 90.80% examples, 44988 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:51,274 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:33:51,330 : INFO : PROGRESS: at 97.72% examples, 46150 words/s, in_qsize 2, out_qsize 1\n",
      "2018-05-06 21:33:51,334 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:33:51,533 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:33:51,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:33:51,573 : INFO : training on 1016989 raw words (1087710 effective words) took 23.4s, 46456 effective words/s\n",
      "2018-05-06 21:33:51,577 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:33:51,580 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:33:51,588 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:33:51,593 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:33:52,081 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:33:52,365 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:33:52,369 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:33:54,010 : INFO : PROGRESS: at 4.82% examples, 32724 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:55,768 : INFO : PROGRESS: at 12.59% examples, 40936 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:57,498 : INFO : PROGRESS: at 20.35% examples, 43739 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:33:58,551 : INFO : PROGRESS: at 25.21% examples, 44890 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:00,139 : INFO : PROGRESS: at 32.00% examples, 45325 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:01,750 : INFO : PROGRESS: at 39.75% examples, 46634 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:03,417 : INFO : PROGRESS: at 47.54% examples, 47318 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:05,068 : INFO : PROGRESS: at 55.25% examples, 47879 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:06,953 : INFO : PROGRESS: at 62.92% examples, 47522 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:07,976 : INFO : PROGRESS: at 69.82% examples, 49173 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:09,559 : INFO : PROGRESS: at 74.82% examples, 47829 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:10,575 : INFO : PROGRESS: at 79.84% examples, 48176 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:11,602 : INFO : PROGRESS: at 85.84% examples, 49012 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:13,303 : INFO : PROGRESS: at 90.80% examples, 47567 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:14,358 : INFO : PROGRESS: at 95.73% examples, 47699 words/s, in_qsize 4, out_qsize 0\n",
      "2018-05-06 21:34:14,446 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:34:14,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:34:14,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:34:14,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:34:14,739 : INFO : training on 1016989 raw words (1087699 effective words) took 22.4s, 48662 effective words/s\n",
      "2018-05-06 21:34:14,743 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:34:14,749 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:34:14,753 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:34:14,759 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:34:15,162 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:34:15,432 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:34:15,434 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:34:16,731 : INFO : PROGRESS: at 0.97% examples, 8271 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:17,857 : INFO : PROGRESS: at 5.79% examples, 26461 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:19,643 : INFO : PROGRESS: at 12.58% examples, 33007 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:20,647 : INFO : PROGRESS: at 16.48% examples, 34818 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:21,723 : INFO : PROGRESS: at 22.30% examples, 39037 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:23,385 : INFO : PROGRESS: at 28.12% examples, 38910 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:24,485 : INFO : PROGRESS: at 33.94% examples, 41258 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:25,695 : INFO : PROGRESS: at 37.82% examples, 40547 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:27,194 : INFO : PROGRESS: at 43.64% examples, 40814 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:28,328 : INFO : PROGRESS: at 49.48% examples, 42185 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:29,856 : INFO : PROGRESS: at 55.25% examples, 42143 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:30,857 : INFO : PROGRESS: at 60.05% examples, 42856 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:32,094 : INFO : PROGRESS: at 64.87% examples, 42849 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:33,129 : INFO : PROGRESS: at 69.82% examples, 43358 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:34,347 : INFO : PROGRESS: at 72.82% examples, 42303 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:35,463 : INFO : PROGRESS: at 76.83% examples, 42139 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:36,470 : INFO : PROGRESS: at 80.84% examples, 42207 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:37,507 : INFO : PROGRESS: at 84.85% examples, 42208 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:38,941 : INFO : PROGRESS: at 90.80% examples, 42350 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:40,119 : INFO : PROGRESS: at 96.73% examples, 42910 words/s, in_qsize 3, out_qsize 1\n",
      "2018-05-06 21:34:40,124 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:34:40,130 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:34:40,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:34:40,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:34:40,302 : INFO : training on 1016989 raw words (1087621 effective words) took 24.9s, 43761 effective words/s\n",
      "2018-05-06 21:34:40,307 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:34:40,310 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:34:40,313 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:34:40,317 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:34:40,691 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:34:40,985 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:34:40,988 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:34:42,086 : INFO : PROGRESS: at 2.89% examples, 29403 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:43,150 : INFO : PROGRESS: at 6.76% examples, 34654 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:44,942 : INFO : PROGRESS: at 12.59% examples, 35129 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:45,986 : INFO : PROGRESS: at 16.48% examples, 36323 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:46,988 : INFO : PROGRESS: at 22.30% examples, 40921 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:48,557 : INFO : PROGRESS: at 28.12% examples, 40876 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:49,570 : INFO : PROGRESS: at 34.91% examples, 44768 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:50,962 : INFO : PROGRESS: at 39.76% examples, 43867 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:52,016 : INFO : PROGRESS: at 43.64% examples, 43534 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:53,019 : INFO : PROGRESS: at 49.48% examples, 45225 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:54,525 : INFO : PROGRESS: at 55.25% examples, 44913 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:55,542 : INFO : PROGRESS: at 61.95% examples, 46894 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:57,033 : INFO : PROGRESS: at 66.83% examples, 45804 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:34:58,110 : INFO : PROGRESS: at 73.83% examples, 47378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:34:59,904 : INFO : PROGRESS: at 78.84% examples, 45786 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:01,611 : INFO : PROGRESS: at 86.83% examples, 46218 words/s, in_qsize 7, out_qsize 1\n",
      "2018-05-06 21:35:03,201 : INFO : PROGRESS: at 94.75% examples, 46732 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-06 21:35:03,258 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:35:03,268 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:35:03,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:35:03,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:35:03,532 : INFO : training on 1016989 raw words (1087715 effective words) took 22.5s, 48279 effective words/s\n",
      "2018-05-06 21:35:03,536 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:35:03,540 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:35:03,544 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:35:03,548 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:35:03,969 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:35:04,248 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:35:04,251 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:35:05,996 : INFO : PROGRESS: at 4.82% examples, 30733 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:07,700 : INFO : PROGRESS: at 12.58% examples, 40321 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:08,732 : INFO : PROGRESS: at 16.48% examples, 40532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:10,343 : INFO : PROGRESS: at 24.24% examples, 43797 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:11,988 : INFO : PROGRESS: at 32.00% examples, 45518 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:13,693 : INFO : PROGRESS: at 39.75% examples, 46281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:15,115 : INFO : PROGRESS: at 47.53% examples, 48061 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:16,177 : INFO : PROGRESS: at 53.33% examples, 49150 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:17,615 : INFO : PROGRESS: at 59.09% examples, 48648 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:19,068 : INFO : PROGRESS: at 66.83% examples, 49573 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:20,537 : INFO : PROGRESS: at 74.82% examples, 50454 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:21,927 : INFO : PROGRESS: at 82.85% examples, 51465 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:22,990 : INFO : PROGRESS: at 87.83% examples, 51411 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:24,302 : INFO : PROGRESS: at 94.75% examples, 51737 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-06 21:35:24,427 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:35:24,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:35:24,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:35:24,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:35:24,662 : INFO : training on 1016989 raw words (1087663 effective words) took 20.4s, 53299 effective words/s\n",
      "2018-05-06 21:35:24,662 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:35:24,677 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:35:24,677 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:35:24,677 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:35:25,052 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:35:25,271 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:35:25,287 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:35:26,771 : INFO : PROGRESS: at 4.82% examples, 36038 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:28,130 : INFO : PROGRESS: at 12.58% examples, 48699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:29,521 : INFO : PROGRESS: at 20.37% examples, 52849 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:31,052 : INFO : PROGRESS: at 28.12% examples, 53592 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:32,787 : INFO : PROGRESS: at 35.88% examples, 52612 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:33,818 : INFO : PROGRESS: at 41.70% examples, 53777 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:35,351 : INFO : PROGRESS: at 47.53% examples, 51922 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:36,346 : INFO : PROGRESS: at 53.33% examples, 52989 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:37,970 : INFO : PROGRESS: at 59.09% examples, 51291 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:39,141 : INFO : PROGRESS: at 62.92% examples, 50002 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:40,235 : INFO : PROGRESS: at 68.82% examples, 50583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:41,246 : INFO : PROGRESS: at 73.83% examples, 50810 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:42,258 : INFO : PROGRESS: at 77.83% examples, 50379 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:43,266 : INFO : PROGRESS: at 81.84% examples, 49991 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:45,001 : INFO : PROGRESS: at 86.84% examples, 48341 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:46,066 : INFO : PROGRESS: at 91.79% examples, 48425 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:47,011 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:35:47,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:35:47,249 : INFO : PROGRESS: at 98.45% examples, 49068 words/s, in_qsize 1, out_qsize 1\n",
      "2018-05-06 21:35:47,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:35:47,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:35:47,267 : INFO : training on 1016989 raw words (1087557 effective words) took 22.0s, 49513 effective words/s\n",
      "2018-05-06 21:35:47,270 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:35:47,274 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:35:47,278 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:35:47,281 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:35:47,691 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:35:47,957 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:35:47,960 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:35:49,098 : INFO : PROGRESS: at 0.95% examples, 9355 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:50,131 : INFO : PROGRESS: at 7.73% examples, 39511 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:51,783 : INFO : PROGRESS: at 12.59% examples, 36371 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:53,521 : INFO : PROGRESS: at 20.35% examples, 40337 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:35:55,220 : INFO : PROGRESS: at 28.12% examples, 42630 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:56,361 : INFO : PROGRESS: at 32.96% examples, 43197 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:58,052 : INFO : PROGRESS: at 39.76% examples, 43364 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:35:59,780 : INFO : PROGRESS: at 47.53% examples, 44231 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:00,836 : INFO : PROGRESS: at 54.29% examples, 46391 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:02,567 : INFO : PROGRESS: at 59.09% examples, 44525 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:03,614 : INFO : PROGRESS: at 65.85% examples, 46278 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:04,739 : INFO : PROGRESS: at 68.82% examples, 45077 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:06,313 : INFO : PROGRESS: at 74.82% examples, 44796 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:07,324 : INFO : PROGRESS: at 79.84% examples, 45290 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:08,985 : INFO : PROGRESS: at 86.84% examples, 45328 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:10,679 : INFO : PROGRESS: at 94.75% examples, 45690 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-06 21:36:10,809 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:36:10,821 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:36:11,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:36:11,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:36:11,061 : INFO : training on 1016989 raw words (1087640 effective words) took 23.1s, 47116 effective words/s\n",
      "2018-05-06 21:36:11,064 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:36:11,068 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:36:11,075 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:36:11,082 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:36:11,454 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:36:11,732 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:36:11,735 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:36:12,939 : INFO : PROGRESS: at 2.87% examples, 26716 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:14,577 : INFO : PROGRESS: at 8.70% examples, 33858 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:16,272 : INFO : PROGRESS: at 16.48% examples, 40046 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:17,898 : INFO : PROGRESS: at 24.24% examples, 43299 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:19,591 : INFO : PROGRESS: at 32.00% examples, 44824 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:21,313 : INFO : PROGRESS: at 39.75% examples, 45662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:22,488 : INFO : PROGRESS: at 43.64% examples, 44637 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:23,575 : INFO : PROGRESS: at 50.45% examples, 46842 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:36:25,071 : INFO : PROGRESS: at 55.25% examples, 45581 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:26,770 : INFO : PROGRESS: at 62.92% examples, 46087 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:27,827 : INFO : PROGRESS: at 69.82% examples, 47681 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:29,421 : INFO : PROGRESS: at 74.82% examples, 46482 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:30,545 : INFO : PROGRESS: at 78.84% examples, 46040 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:31,607 : INFO : PROGRESS: at 82.85% examples, 45783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-06 21:36:32,642 : INFO : PROGRESS: at 86.84% examples, 45586 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-06 21:36:34,323 : INFO : PROGRESS: at 94.75% examples, 45959 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-06 21:36:34,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-06 21:36:34,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-06 21:36:34,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-06 21:36:34,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-06 21:36:34,668 : INFO : training on 1016989 raw words (1087718 effective words) took 22.9s, 47464 effective words/s\n",
      "2018-05-06 21:36:34,671 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-06 21:36:34,677 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-06 21:36:34,681 : INFO : not storing attribute syn0norm\n",
      "2018-05-06 21:36:34,687 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-06 21:36:35,063 : INFO : not storing attribute cum_table\n",
      "2018-05-06 21:36:35,356 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "\n",
    "#iter = 1, because we keep training ourselves :)\n",
    "model = Doc2Vec(size=80, dbow_words= 1, dm=0, iter=1,  window=2, seed=1337, min_count=6, \n",
    "                workers=4,alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(documents)\n",
    "for epoch in range(10):\n",
    "    print(\"epoch \"+str(epoch))\n",
    "    model.train(documents, total_examples=count, epochs=1)\n",
    "    model.save('noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model')\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-06 21:53:04,414 : INFO : loading Doc2Vec object from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-06 21:53:04,649 : INFO : loading wv recursively from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.wv.* with mmap=None\n",
      "2018-05-06 21:53:04,649 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-06 21:53:04,664 : INFO : loading docvecs recursively from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.* with mmap=None\n",
      "2018-05-06 21:53:04,664 : INFO : loading doctag_syn0 from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2018-05-06 21:53:04,836 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-06 21:53:04,836 : INFO : loaded noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec.load('noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('олимпиада', 0.7108860015869141),\n",
       " ('пи', 0.7027755975723267),\n",
       " ('паралимпиада', 0.6913758516311646),\n",
       " ('пхенчхан', 0.6395276784896851),\n",
       " ('финал', 0.6351224780082703),\n",
       " ('хоккеист', 0.6099418997764587),\n",
       " ('1992', 0.6050775647163391),\n",
       " ('керлингист', 0.5994738340377808),\n",
       " ('лёд', 0.5924407243728638),\n",
       " ('немец', 0.5889979600906372)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('ои')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk, math, codecs\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "import re\n",
    "import pymorphy2\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "fname = 'noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model'\n",
    "\n",
    "model = Doc2Vec.load(fname)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read().split('\\n')\n",
    "stw = set(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:13.619497\n"
     ]
    }
   ],
   "source": [
    "#lemmatized test\n",
    "\n",
    "start_time = datetime.now()\n",
    "corpus = codecs.open('test_headlines_short.txt', mode=\"r\", encoding=\"utf-8\")\n",
    "lines = corpus.read().lower().split('\\r\\n')\n",
    "lemm_lines = []\n",
    "for line in lines:\n",
    "    fixed = ''.join([x if x.isalnum() or x.isspace() else \" \" for x in line ]).split()\n",
    "    fixedNoStop = []\n",
    "    for fix in fixed:\n",
    "        if fix not in stw:\n",
    "            fix = morph.parse(fix)[0].normal_form\n",
    "            fixedNoStop.append(fix)\n",
    "    lemm_lines.append(fixedNoStop)\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['актера бена аффлека обвинили в сексуальных домогательствах', 'рфпи заключит сделку с ближневосточными фондами по покупке доли в \"пулково\"', 'вс признал законным приговор жителю эстонии за шпионаж в россии', 'марсово поле в петербурге исключили из списка гайд-парков', 'при землетрясении в китае могли погибнуть сотни человек', 'выработка электроэнергии станциями сгк в первом полугодии снизилась на 8%', 'битва буша с дождевиком на инаугурации трампа вызвала волну шуток в интернете', 'собчак открыла штаб в екатеринбурге', 'в правительстве объяснили расширение списка продэмбарго', 'источник: пять человек остаются в больницах после аварии поездов москве']\n"
     ]
    }
   ],
   "source": [
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferring vectors\n",
      "done\n",
      "Cluster assigning done!\n",
      "Duration: 0:18:38.780532\n"
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS = 30 #25\n",
    "\n",
    "def preprocess(str):\n",
    "    # remove links\n",
    "    str = re.sub(r'http(s)?:\\/\\/\\S*? ', \"\", str)\n",
    "    return str\n",
    "\n",
    "\n",
    "def preprocess_document(text):\n",
    "    #text = preprocess(text)\n",
    "    fixedNoStop = []\n",
    "    fixed = ''.join([x if x.isalnum() or x.isspace() else \" \" for x in text ]).split()\n",
    "    for fix in fixed:\n",
    "        if fix not in stw:\n",
    "            fix = morph.parse(fix)[0].normal_form\n",
    "            fixedNoStop.append(fix)\n",
    "    return fixedNoStop\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "#data = <sparse matrix that you would normally give to scikit>.toarray()\n",
    "\n",
    "corpus = codecs.open('test_headlines_short.txt', mode=\"r\", encoding=\"utf-8\")\n",
    "lines = corpus.read().lower().split('\\r\\n')\n",
    "count = len(lines)\n",
    "\n",
    "vectors = []\n",
    "\n",
    "print(\"inferring vectors\")\n",
    "duplicate_dict = {}\n",
    "used_lines = []\n",
    "for i, t in enumerate(lines):\n",
    "    if t not in duplicate_dict:#i % 2 == 0 and\n",
    "        duplicate_dict[t] = True\n",
    "        used_lines.append(t)\n",
    "        vectors.append(model.infer_vector(preprocess_document(t)))\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(vectors, assign_clusters=True)\n",
    "print('Cluster assigning done!')\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "#    txt = f.read()\n",
    "#stw = txt.split('\\n')\n",
    "\n",
    "clustersizes = []\n",
    "\n",
    "def distanceToCentroid():\n",
    "    for i in range(0,NUM_CLUSTERS):\n",
    "        clustersize = 0\n",
    "        for j in range(0,len(assigned_clusters)):\n",
    "            if (assigned_clusters[j] == i):\n",
    "                clustersize+=1\n",
    "        clustersizes.append(clustersize)\n",
    "        dist = 0.0\n",
    "        centr = kclusterer.means()[i]\n",
    "        for j in range(0,len(assigned_clusters)):\n",
    "            if (assigned_clusters[j] == i):\n",
    "                dist += pow(nltk.cluster.util.cosine_distance(vectors[j], centr),2)/clustersize\n",
    "        dist = math.sqrt(dist)\n",
    "        print(\"distance cluster: \"+str(i)+\" RMSE: \"+str(dist)+\" clustersize: \"+str(clustersize))\n",
    "\n",
    "\n",
    "\n",
    "def get_titles_by_cluster(id):\n",
    "    list = []\n",
    "    for x in range(0, len(assigned_clusters)):\n",
    "        if (assigned_clusters[x] == id):\n",
    "            list.append(used_lines[x])\n",
    "    return list\n",
    "\n",
    "def get_topics(titles, stw):\n",
    "    from collections import Counter\n",
    "    words = [preprocess_document(x) for x in titles]\n",
    "    words = [word for sublist in words for word in sublist]\n",
    "    filtered_words = [word for word in words if word not in stw]\n",
    "    count = Counter(filtered_words)\n",
    "    print(count.most_common()[:5])\n",
    "\n",
    "\n",
    "def cluster_to_topics(id):\n",
    "    get_topics(get_titles_by_cluster(id), stw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('рубль', 9), ('миллиард', 8), ('рассказать', 7), ('долг', 4), ('доллар', 4)]\n",
      "[('теракт', 14), ('иго', 9), ('заявить', 8), ('турция', 7), ('боевик', 7)]\n",
      "[('каталония', 8), ('оппозиция', 7), ('заявить', 5), ('венесуэла', 5), ('поддержка', 4)]\n",
      "[('рубль', 11), ('миллион', 7), ('вырасти', 7), ('миллиард', 7), ('2017', 6)]\n",
      "[('память', 4), ('рассказать', 4), ('игра', 4), ('путин', 4), ('назвать', 4)]\n",
      "[('метро', 7), ('московский', 6), ('станция', 5), ('поезд', 4), ('петербург', 4)]\n",
      "[('путин', 24), ('встреча', 22), ('сша', 12), ('мид', 11), ('тиллерсон', 10)]\n",
      "[('рассказать', 9), ('рост', 8), ('путин', 7), ('нефть', 7), ('заявить', 7)]\n",
      "[('выборы', 14), ('выбор', 12), ('макрон', 10), ('президент', 9), ('франция', 8)]\n",
      "[('ес', 15), ('мид', 13), ('заявить', 12), ('сша', 11), ('сотрудничество', 9)]\n",
      "[('полиция', 11), ('задержать', 10), ('ск', 6), ('убийство', 6), ('подозревать', 6)]\n",
      "[('кндр', 35), ('сша', 26), ('заявить', 15), ('китай', 12), ('япония', 10)]\n",
      "[('заявить', 11), ('путин', 10), ('рассказать', 9), ('власть', 6), ('пообещать', 5)]\n",
      "[('сообщить', 12), ('сми', 10), ('сообщение', 9), ('источник', 9), ('проверять', 8)]\n",
      "[('мужчина', 19), ('ребёнок', 14), ('полицейский', 12), ('задержать', 12), ('подросток', 8)]\n",
      "[('суд', 30), ('экс', 15), ('глава', 11), ('арест', 8), ('приговор', 7)]\n",
      "[('президент', 19), ('глава', 15), ('министр', 12), ('пост', 11), ('губернатор', 10)]\n",
      "[('пожар', 18), ('произойти', 13), ('землетрясение', 12), ('область', 8), ('ливень', 7)]\n",
      "[('центр', 8), ('построить', 5), ('петербург', 4), ('программа', 4), ('взрыв', 4)]\n",
      "[('российский', 18), ('самолёт', 11), ('военный', 7), ('сша', 6), ('крушение', 5)]\n",
      "[('сша', 34), ('отношение', 18), ('санкция', 15), ('заявить', 13), ('рассказать', 9)]\n",
      "[('взрыв', 24), ('пострадавший', 24), ('число', 15), ('погибнуть', 9), ('петербург', 9)]\n",
      "[('трамп', 31), ('сша', 13), ('иран', 5), ('сми', 5), ('американский', 5)]\n",
      "[('днр', 18), ('силовик', 17), ('заявить', 17), ('сообщить', 13), ('сутки', 11)]\n",
      "[('предложить', 9), ('госдума', 7), ('подготовить', 4), ('принять', 4), ('система', 4)]\n",
      "[('проект', 9), ('одобрить', 7), ('закон', 7), ('госдума', 7), ('правительство', 6)]\n",
      "[('погибнуть', 29), ('дтп', 26), ('автобус', 19), ('ребёнок', 9), ('пострадать', 7)]\n",
      "[('украина', 25), ('киев', 14), ('украинский', 14), ('крым', 13), ('порошенко', 10)]\n",
      "[('донбасс', 30), ('днр', 14), ('заявить', 13), ('киев', 12), ('лнр', 11)]\n",
      "[('сша', 15), ('оон', 12), ('назвать', 8), ('право', 6), ('решение', 6)]\n"
     ]
    }
   ],
   "source": [
    "for clstr in range(30):\n",
    "    cluster_to_topics(clstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в германии проходят парламентские выборы',\n",
       " 'аналитик: скандал вокруг жены может помешать фийону в президентской гонке',\n",
       " 'почти половина британцев поддержала отставку мэй, показал опрос',\n",
       " 'академия наук франции призвала голосовать за макрона во втором туре',\n",
       " 'по оценке телеканала france 2, фийон и меланшон не проходят во второй тур',\n",
       " 'компромисс или раздор: как в молдавии утверждали смешанную систему выборов',\n",
       " 'рейтинг ле пен упал на один пункт перед вторым туром выборов, показал опрос',\n",
       " 'глава белоруссии поздравил жээнбекова с избранием президентом киргизии',\n",
       " 'путин гарантировал абхазии независимость и самостоятельность',\n",
       " 'москве импонирует победа вучича на выборах в сербии, заявили в кремле',\n",
       " 'депутат бундестага: германия не забудет о роли коля в объединении страны',\n",
       " 'путин: нет никаких доказательств вмешательства россии в выборы в сша',\n",
       " 'лавров прокомментировал слова макрона про sputnik и rt',\n",
       " 'более трети россиян надеются на улучшение жизни через пять лет, показал опрос',\n",
       " 'в эквадоре стартовали выборы президента',\n",
       " 'жюппе опроверг слухи о том, что он заменит фийона в президентской гонке',\n",
       " 'макрон представил программу на выборах президента франции',\n",
       " 'опрос показал, доверяют ли россияне благотворительным организациям',\n",
       " '\"дух поражения\" и \"война против всех\": как прошли дебаты макрона и ле пен',\n",
       " 'на выборах армении лидирует правящая партия с 52,12%, сообщили в цик страны',\n",
       " 'ален делон призвал голосовать за фийона на выборах во франции',\n",
       " 'в lse рассказали, почему кибератаки на британских выборах невозможны',\n",
       " 'две трети россиян хотят видеть путина президентом после 2018 года, показал опрос',\n",
       " 'exit poll: правящая партия индии лидирует на выборах в крупнейшем штате',\n",
       " 'макрон заявил, что уважает путина и готов откровенно с ним говорить',\n",
       " 'в киргизии открылись избирательные участки на выборах президента',\n",
       " 'британские консерваторы остановят предвыборную кампанию из-за взрыва в манчестере',\n",
       " 'макрона во втором туре выборов во франции поддержат 61% избирателей, показал опрос',\n",
       " 'в кремле поддержали решение об участии российских спортсменов в олимпиаде',\n",
       " 'народная партия лидирует на выборах в австрии',\n",
       " 'люди ждали выдвижения путина в президенты, заявила поклонская',\n",
       " 'путин примет участие в открытии конференции воз по туберкулезу',\n",
       " 'чешский президент поздравил макрона с избранием главой франции',\n",
       " 'сми рассказали, кто мог совершить кибератаку на сеть британского парламента',\n",
       " 'сторонники ле пен и журналисты собрались у ее штаба',\n",
       " 'в москве к 18.00 проголосовали 12% избирателей',\n",
       " 'путин вручил паспорта десяти юным россиянам, успешно проявившим себя',\n",
       " 'блок меркель лидирует после подсчета голосов в 227 округах',\n",
       " 'политологи рассказали, что поможет повысить явку на выборах',\n",
       " 'в оп партии обвинили в использовании \"грязных технологий\" перед выборами',\n",
       " 'немецкий эксперт: предвыборная кампания в фрг завершена, меркель победит',\n",
       " 'парнас начал консультации по единому кандидату в президенты',\n",
       " 'rt стал участником первых пятисторонних дебатов телеканалов стран брикс',\n",
       " '\"нормандская четверка\" надеется сохранить формат после выборов во франции',\n",
       " 'эксперт уверен, что олимпиада в южной корее \"пройдет спокойно\"',\n",
       " 'сми: макрон подал в суд на фотографа, следившего за ним во время отпуска',\n",
       " 'ле пен обгонит макрона в первом туре выборов, показал опрос',\n",
       " 'американец и финн будут судить хоккейный финал ои россия - германия',\n",
       " 'коалиция британских консерваторов с dup может \"смягчить\" brexit',\n",
       " 'глава британских либерал-демократов пообещал отменить brexit',\n",
       " 'во франции назвали провалом низкую явку в i туре парламентских выборов',\n",
       " 'туркмения отмечает день победы',\n",
       " 'французские \"республиканцы\" выступят с \"инициативой\" по фийону',\n",
       " 'титов рассказал о стратегии в партии роста на выборах-2018',\n",
       " 'в германии состоятся выборы в парламент самой северной земли',\n",
       " 'слуцкий пожелал успехов французской оппозиции на выборах в нацсобрание',\n",
       " 'глава штаба собчак считает, что она не уйдет из политики после выборов-2018',\n",
       " 'активистка femen заявила о распаде движения',\n",
       " 'трамп поздравил макрона с победой на выборах во франции',\n",
       " 'worldskills: 80% выпускников в россии должны представлять рабочие профессии',\n",
       " 'ле пен проголосовала на выборах президента. прямая трансляция',\n",
       " 'премьер албании провозгласил победу своей партии на парламентских выборах',\n",
       " 'в россии завершается финальный этап формирования общественной палаты']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_titles_by_cluster(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance cluster: 0 RMSE: 0.34556933743794466 clustersize: 54\n",
      "distance cluster: 1 RMSE: 0.3528981227558469 clustersize: 63\n",
      "distance cluster: 2 RMSE: 0.3390824584165182 clustersize: 40\n",
      "distance cluster: 3 RMSE: 0.3220099381149507 clustersize: 78\n",
      "distance cluster: 4 RMSE: 0.3634730756012227 clustersize: 70\n",
      "distance cluster: 5 RMSE: 0.33283500446726594 clustersize: 58\n",
      "distance cluster: 6 RMSE: 0.3100571960331825 clustersize: 80\n",
      "distance cluster: 7 RMSE: 0.3241008842732013 clustersize: 84\n",
      "distance cluster: 8 RMSE: 0.31014477452878925 clustersize: 63\n",
      "distance cluster: 9 RMSE: 0.3242564380523431 clustersize: 102\n",
      "distance cluster: 10 RMSE: 0.33650713890331685 clustersize: 59\n",
      "distance cluster: 11 RMSE: 0.3269431076504982 clustersize: 87\n",
      "distance cluster: 12 RMSE: 0.3558726625155311 clustersize: 61\n",
      "distance cluster: 13 RMSE: 0.3365885567978864 clustersize: 65\n",
      "distance cluster: 14 RMSE: 0.3093931754714953 clustersize: 124\n",
      "distance cluster: 15 RMSE: 0.3249165101006558 clustersize: 90\n",
      "distance cluster: 16 RMSE: 0.33045655298088433 clustersize: 74\n",
      "distance cluster: 17 RMSE: 0.3130293305014642 clustersize: 93\n",
      "distance cluster: 18 RMSE: 0.3421758890323151 clustersize: 74\n",
      "distance cluster: 19 RMSE: 0.35663171322491405 clustersize: 77\n",
      "distance cluster: 20 RMSE: 0.31894360404179084 clustersize: 87\n",
      "distance cluster: 21 RMSE: 0.28992565271311854 clustersize: 83\n",
      "distance cluster: 22 RMSE: 0.3414648199888005 clustersize: 54\n",
      "distance cluster: 23 RMSE: 0.28847209655974 clustersize: 56\n",
      "distance cluster: 24 RMSE: 0.32817638458858295 clustersize: 51\n",
      "distance cluster: 25 RMSE: 0.32367678042957054 clustersize: 66\n",
      "distance cluster: 26 RMSE: 0.29660124921684927 clustersize: 95\n",
      "distance cluster: 27 RMSE: 0.33827814761317887 clustersize: 83\n",
      "distance cluster: 28 RMSE: 0.31478807287502375 clustersize: 71\n",
      "distance cluster: 29 RMSE: 0.34748017111640706 clustersize: 68\n"
     ]
    }
   ],
   "source": [
    "distanceToCentroid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
