{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import re\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "import pymorphy2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "stw = set(txt.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:08:56,454 : INFO : Loading dictionaries from C:\\Anaconda\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2018-05-29 00:08:56,772 : INFO : format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:08:40.452417\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def preprocess(str):\n",
    "    '''leave only words'''\n",
    "    str = re.sub(r'[^а-яёА-ЯЁ \\-]+', '', str)\n",
    "\n",
    "    return str\n",
    "\n",
    "class Documents(object):\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            yield TaggedDocument(words = doc, tags = [i])\n",
    "\n",
    "file = 'train_headlines.txt'\n",
    "\n",
    "\n",
    "corpus = open(file, \"r\", encoding='utf-8')\n",
    "lines = corpus.read().lower().split(\"\\n\")\n",
    "count = len(lines)\n",
    "preprocessed = []\n",
    "\n",
    "duplicate_dict = {}\n",
    "\n",
    "for t in lines:\n",
    "    if t not in duplicate_dict:\n",
    "        duplicate_dict[t] = True\n",
    "        #t = preprocess(t)\n",
    "        fixedNoStop = []\n",
    "        fixed =''.join([x if x.isalnum() or x.isspace() else \" \" for x in t ]).split()\n",
    "        for fix in fixed:\n",
    "            if fix not in stw:\n",
    "                fix = morph.parse(fix)[0].normal_form\n",
    "                fixedNoStop.append(fix)\n",
    "        preprocessed.append(fixedNoStop)\n",
    "\n",
    "documents = Documents(preprocessed)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:18:08,135 : INFO : collecting all words and their counts\n",
      "2018-05-29 00:18:08,135 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-05-29 00:18:08,291 : INFO : PROGRESS: at example #10000, processed 70313 words (479504/s), 9299 word types, 10000 tags\n",
      "2018-05-29 00:18:08,400 : INFO : PROGRESS: at example #20000, processed 140114 words (659988/s), 12398 word types, 20000 tags\n",
      "2018-05-29 00:18:08,510 : INFO : PROGRESS: at example #30000, processed 209942 words (651603/s), 14741 word types, 30000 tags\n",
      "2018-05-29 00:18:08,619 : INFO : PROGRESS: at example #40000, processed 279980 words (683735/s), 16598 word types, 40000 tags\n",
      "2018-05-29 00:18:08,728 : INFO : PROGRESS: at example #50000, processed 349973 words (648786/s), 18080 word types, 50000 tags\n",
      "2018-05-29 00:18:08,838 : INFO : PROGRESS: at example #60000, processed 419910 words (632291/s), 19352 word types, 60000 tags\n",
      "2018-05-29 00:18:08,947 : INFO : PROGRESS: at example #70000, processed 489711 words (708735/s), 20519 word types, 70000 tags\n",
      "2018-05-29 00:18:09,072 : INFO : PROGRESS: at example #80000, processed 560052 words (602879/s), 22517 word types, 80000 tags\n",
      "2018-05-29 00:18:09,166 : INFO : PROGRESS: at example #90000, processed 630908 words (730682/s), 24248 word types, 90000 tags\n",
      "2018-05-29 00:18:09,275 : INFO : PROGRESS: at example #100000, processed 700506 words (607864/s), 25390 word types, 100000 tags\n",
      "2018-05-29 00:18:09,400 : INFO : PROGRESS: at example #110000, processed 768258 words (591492/s), 26945 word types, 110000 tags\n",
      "2018-05-29 00:18:09,510 : INFO : PROGRESS: at example #120000, processed 835970 words (626329/s), 27854 word types, 120000 tags\n",
      "2018-05-29 00:18:09,619 : INFO : PROGRESS: at example #130000, processed 903995 words (692596/s), 29127 word types, 130000 tags\n",
      "2018-05-29 00:18:09,744 : INFO : PROGRESS: at example #140000, processed 972667 words (563496/s), 30680 word types, 140000 tags\n",
      "2018-05-29 00:18:09,806 : INFO : collected 31479 word types and 146487 unique tags from a corpus of 146487 examples and 1016989 words\n",
      "2018-05-29 00:18:09,822 : INFO : Loading a fresh vocabulary\n",
      "2018-05-29 00:18:09,916 : INFO : min_count=6 retains 11122 unique words (35% of original 31479, drops 20357)\n",
      "2018-05-29 00:18:09,916 : INFO : min_count=6 leaves 979143 word corpus (96% of original 1016989, drops 37846)\n",
      "2018-05-29 00:18:10,010 : INFO : deleting the raw counts dictionary of 31479 items\n",
      "2018-05-29 00:18:10,025 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2018-05-29 00:18:10,025 : INFO : downsampling leaves estimated 941148 word corpus (96.1% of prior 979143)\n",
      "2018-05-29 00:18:10,025 : INFO : estimated required memory for 11122 words and 80 dimensions: 59554920 bytes\n",
      "2018-05-29 00:18:10,119 : INFO : resetting layer weights\n",
      "2018-05-29 00:18:14,322 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:18:15,838 : INFO : PROGRESS: at 4.82% examples, 42575 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:17,010 : INFO : PROGRESS: at 12.58% examples, 56956 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:18,197 : INFO : PROGRESS: at 20.37% examples, 61981 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:19,541 : INFO : PROGRESS: at 28.12% examples, 62316 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:20,713 : INFO : PROGRESS: at 35.88% examples, 64275 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:21,916 : INFO : PROGRESS: at 43.64% examples, 65433 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:23,056 : INFO : PROGRESS: at 51.41% examples, 66697 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:24,244 : INFO : PROGRESS: at 59.09% examples, 67301 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:25,306 : INFO : PROGRESS: at 65.85% examples, 67546 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:26,394 : INFO : PROGRESS: at 71.83% examples, 66749 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:27,425 : INFO : PROGRESS: at 78.84% examples, 67392 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:28,440 : INFO : PROGRESS: at 85.84% examples, 67992 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:29,503 : INFO : PROGRESS: at 91.79% examples, 67402 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:30,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:18:30,206 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:18:30,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:18:30,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:18:30,315 : INFO : training on 1016989 raw words (1087687 effective words) took 15.7s, 69138 effective words/s\n",
      "2018-05-29 00:18:30,315 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:18:30,315 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:18:30,331 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:18:30,331 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:18:30,722 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:18:30,909 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:18:30,925 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:18:32,362 : INFO : PROGRESS: at 4.82% examples, 37276 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:33,534 : INFO : PROGRESS: at 12.59% examples, 53358 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:34,722 : INFO : PROGRESS: at 20.35% examples, 59040 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:35,894 : INFO : PROGRESS: at 28.12% examples, 62225 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:37,253 : INFO : PROGRESS: at 35.88% examples, 62420 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:38,425 : INFO : PROGRESS: at 43.64% examples, 64027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:39,675 : INFO : PROGRESS: at 51.41% examples, 64562 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:40,956 : INFO : PROGRESS: at 59.09% examples, 64785 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:42,222 : INFO : PROGRESS: at 66.83% examples, 65033 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:43,253 : INFO : PROGRESS: at 73.83% examples, 65821 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:44,300 : INFO : PROGRESS: at 78.84% examples, 64699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:45,612 : INFO : PROGRESS: at 86.84% examples, 64856 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:46,828 : INFO : PROGRESS: at 94.75% examples, 65287 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 00:18:46,984 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:18:47,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:18:47,141 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:18:47,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:18:47,172 : INFO : training on 1016989 raw words (1087667 effective words) took 16.2s, 67001 effective words/s\n",
      "2018-05-29 00:18:47,172 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:18:47,172 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:18:47,172 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:18:47,187 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:18:47,562 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:18:47,781 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:18:47,781 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:18:49,047 : INFO : PROGRESS: at 4.82% examples, 42762 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:50,091 : INFO : PROGRESS: at 10.64% examples, 51090 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:51,262 : INFO : PROGRESS: at 16.48% examples, 52351 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:52,559 : INFO : PROGRESS: at 24.24% examples, 55956 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:53,825 : INFO : PROGRESS: at 32.00% examples, 58485 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:55,091 : INFO : PROGRESS: at 39.76% examples, 59994 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:56,497 : INFO : PROGRESS: at 47.54% examples, 60046 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:18:57,700 : INFO : PROGRESS: at 55.25% examples, 61425 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:18:58,950 : INFO : PROGRESS: at 62.92% examples, 62132 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:00,278 : INFO : PROGRESS: at 70.83% examples, 62376 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:01,575 : INFO : PROGRESS: at 78.84% examples, 62852 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:03,075 : INFO : PROGRESS: at 86.84% examples, 62349 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:04,356 : INFO : PROGRESS: at 94.75% examples, 62681 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 00:19:04,403 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:19:04,403 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:19:04,544 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:19:04,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:19:04,591 : INFO : training on 1016989 raw words (1087786 effective words) took 16.8s, 64805 effective words/s\n",
      "2018-05-29 00:19:04,591 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:19:04,591 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:19:04,606 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:19:04,606 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:19:04,997 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:19:05,200 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:19:05,216 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:19:06,632 : INFO : PROGRESS: at 4.82% examples, 37771 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:07,976 : INFO : PROGRESS: at 12.59% examples, 50182 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:09,522 : INFO : PROGRESS: at 20.37% examples, 52100 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:10,866 : INFO : PROGRESS: at 28.12% examples, 54733 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:12,147 : INFO : PROGRESS: at 35.88% examples, 56961 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:13,554 : INFO : PROGRESS: at 43.64% examples, 57594 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:14,757 : INFO : PROGRESS: at 51.41% examples, 59278 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:16,101 : INFO : PROGRESS: at 59.09% examples, 59713 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:17,304 : INFO : PROGRESS: at 66.83% examples, 60745 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:18,554 : INFO : PROGRESS: at 74.82% examples, 61610 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:19,819 : INFO : PROGRESS: at 82.85% examples, 62275 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:21,054 : INFO : PROGRESS: at 90.80% examples, 62830 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:21,741 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:19:21,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:19:21,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:19:21,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:19:21,960 : INFO : training on 1016989 raw words (1087641 effective words) took 16.7s, 65001 effective words/s\n",
      "2018-05-29 00:19:21,960 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:19:21,976 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:19:21,976 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:19:21,991 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:19:22,398 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:19:22,601 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:19:22,601 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:19:24,007 : INFO : PROGRESS: at 4.81% examples, 43928 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:25,257 : INFO : PROGRESS: at 12.58% examples, 55980 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:26,460 : INFO : PROGRESS: at 20.37% examples, 60884 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:27,829 : INFO : PROGRESS: at 28.12% examples, 61292 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:29,079 : INFO : PROGRESS: at 35.88% examples, 62767 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:30,235 : INFO : PROGRESS: at 43.64% examples, 64362 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:31,485 : INFO : PROGRESS: at 51.41% examples, 64949 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:32,720 : INFO : PROGRESS: at 59.09% examples, 65394 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:34,204 : INFO : PROGRESS: at 66.83% examples, 64327 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:35,501 : INFO : PROGRESS: at 74.82% examples, 64627 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:36,829 : INFO : PROGRESS: at 82.85% examples, 64730 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:38,141 : INFO : PROGRESS: at 90.80% examples, 64838 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:38,782 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:19:38,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:19:38,923 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:19:38,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:19:38,970 : INFO : training on 1016989 raw words (1087793 effective words) took 16.2s, 67222 effective words/s\n",
      "2018-05-29 00:19:38,985 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:19:38,985 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:19:38,985 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:19:39,001 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:19:39,407 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:19:39,610 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:19:39,610 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:19:41,063 : INFO : PROGRESS: at 4.82% examples, 37293 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:42,235 : INFO : PROGRESS: at 12.59% examples, 53174 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:43,438 : INFO : PROGRESS: at 20.37% examples, 58741 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:44,626 : INFO : PROGRESS: at 28.12% examples, 61803 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:46,016 : INFO : PROGRESS: at 35.88% examples, 61747 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:47,245 : INFO : PROGRESS: at 43.64% examples, 62941 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:48,448 : INFO : PROGRESS: at 51.41% examples, 64091 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:49,682 : INFO : PROGRESS: at 59.09% examples, 64649 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:50,979 : INFO : PROGRESS: at 66.83% examples, 64741 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:52,057 : INFO : PROGRESS: at 71.83% examples, 63492 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:53,151 : INFO : PROGRESS: at 78.84% examples, 63966 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:19:54,495 : INFO : PROGRESS: at 86.84% examples, 64104 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:55,667 : INFO : PROGRESS: at 94.75% examples, 64681 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 00:19:55,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:19:55,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:19:56,073 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:19:56,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:19:56,089 : INFO : training on 1016989 raw words (1087388 effective words) took 16.4s, 66104 effective words/s\n",
      "2018-05-29 00:19:56,089 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:19:56,089 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:19:56,104 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:19:56,104 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:19:56,511 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:19:56,714 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:19:56,729 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:19:58,026 : INFO : PROGRESS: at 4.82% examples, 41028 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:19:59,464 : INFO : PROGRESS: at 12.59% examples, 50623 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:00,745 : INFO : PROGRESS: at 20.35% examples, 55782 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:01,964 : INFO : PROGRESS: at 28.12% examples, 59113 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:03,229 : INFO : PROGRESS: at 35.88% examples, 60708 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:04,432 : INFO : PROGRESS: at 43.64% examples, 62248 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:05,886 : INFO : PROGRESS: at 51.41% examples, 61749 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:07,135 : INFO : PROGRESS: at 59.09% examples, 62487 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:08,379 : INFO : PROGRESS: at 66.83% examples, 63033 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:09,692 : INFO : PROGRESS: at 74.82% examples, 63363 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:10,707 : INFO : PROGRESS: at 80.84% examples, 63511 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:11,926 : INFO : PROGRESS: at 86.84% examples, 62708 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:13,114 : INFO : PROGRESS: at 94.75% examples, 63338 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 00:20:13,223 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:20:13,223 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:20:13,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:20:13,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:20:13,411 : INFO : training on 1016989 raw words (1087593 effective words) took 16.7s, 65240 effective words/s\n",
      "2018-05-29 00:20:13,411 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:20:13,411 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:20:13,426 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:20:13,426 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:20:13,786 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:20:13,989 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:20:13,989 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:20:15,223 : INFO : PROGRESS: at 4.82% examples, 43819 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:16,458 : INFO : PROGRESS: at 12.59% examples, 56381 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:17,848 : INFO : PROGRESS: at 20.37% examples, 58174 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:19,129 : INFO : PROGRESS: at 28.12% examples, 60248 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:20,317 : INFO : PROGRESS: at 35.88% examples, 62482 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:21,567 : INFO : PROGRESS: at 43.64% examples, 63439 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:22,801 : INFO : PROGRESS: at 51.41% examples, 64268 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:24,145 : INFO : PROGRESS: at 59.09% examples, 64156 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:25,364 : INFO : PROGRESS: at 66.83% examples, 64674 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:26,598 : INFO : PROGRESS: at 74.82% examples, 65228 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:27,833 : INFO : PROGRESS: at 82.85% examples, 65746 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:29,186 : INFO : PROGRESS: at 90.80% examples, 65537 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:29,952 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:20:29,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:20:30,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:20:30,139 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:20:30,139 : INFO : training on 1016989 raw words (1087621 effective words) took 16.1s, 67456 effective words/s\n",
      "2018-05-29 00:20:30,139 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:20:30,139 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:20:30,155 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:20:30,155 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:20:30,546 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:20:30,749 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:20:30,749 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:20:32,030 : INFO : PROGRESS: at 4.82% examples, 42038 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:33,217 : INFO : PROGRESS: at 12.59% examples, 56482 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:34,421 : INFO : PROGRESS: at 20.35% examples, 61228 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:35,811 : INFO : PROGRESS: at 28.12% examples, 61312 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:36,999 : INFO : PROGRESS: at 35.88% examples, 63351 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:38,217 : INFO : PROGRESS: at 43.64% examples, 64462 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:39,405 : INFO : PROGRESS: at 51.41% examples, 65381 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:40,608 : INFO : PROGRESS: at 59.09% examples, 66088 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:42,014 : INFO : PROGRESS: at 66.83% examples, 65302 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:43,342 : INFO : PROGRESS: at 74.82% examples, 65313 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:44,749 : INFO : PROGRESS: at 82.85% examples, 65061 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:46,124 : INFO : PROGRESS: at 90.80% examples, 64831 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:47,108 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:20:47,186 : INFO : PROGRESS: at 97.72% examples, 65147 words/s, in_qsize 2, out_qsize 1\n",
      "2018-05-29 00:20:47,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:20:47,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:20:47,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:20:47,436 : INFO : training on 1016989 raw words (1087846 effective words) took 16.7s, 65312 effective words/s\n",
      "2018-05-29 00:20:47,436 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:20:47,436 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:20:47,452 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:20:47,452 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:20:47,858 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:20:48,092 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:20:48,092 : INFO : training model with 4 workers on 11122 vocabulary and 80 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:20:49,686 : INFO : PROGRESS: at 4.83% examples, 33865 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:50,936 : INFO : PROGRESS: at 12.59% examples, 48969 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:52,498 : INFO : PROGRESS: at 20.35% examples, 50954 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:54,014 : INFO : PROGRESS: at 28.12% examples, 52334 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:55,279 : INFO : PROGRESS: at 34.91% examples, 53551 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:56,608 : INFO : PROGRESS: at 39.76% examples, 51448 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:20:57,983 : INFO : PROGRESS: at 47.53% examples, 52937 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:20:59,529 : INFO : PROGRESS: at 55.25% examples, 53171 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:21:00,545 : INFO : PROGRESS: at 61.95% examples, 54872 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:21:01,967 : INFO : PROGRESS: at 66.83% examples, 53026 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:21:03,467 : INFO : PROGRESS: at 74.82% examples, 53533 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:21:04,733 : INFO : PROGRESS: at 82.84% examples, 54711 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-29 00:21:05,951 : INFO : PROGRESS: at 90.80% examples, 55794 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-29 00:21:06,561 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-29 00:21:06,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 00:21:06,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 00:21:06,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 00:21:06,826 : INFO : training on 1016989 raw words (1087719 effective words) took 18.7s, 58153 effective words/s\n",
      "2018-05-29 00:21:06,826 : WARNING : supplied example count (146487) did not equal expected count (147308)\n",
      "2018-05-29 00:21:06,826 : INFO : saving Doc2Vec object under noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model, separately None\n",
      "2018-05-29 00:21:06,826 : INFO : not storing attribute syn0norm\n",
      "2018-05-29 00:21:06,826 : INFO : storing np array 'doctag_syn0' to noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy\n",
      "2018-05-29 00:21:07,248 : INFO : not storing attribute cum_table\n",
      "2018-05-29 00:21:07,451 : INFO : saved noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "\n",
    "model = Doc2Vec(size=80, dbow_words= 1, dm=0, iter=1,  window=2, seed=1337, min_count=6, \n",
    "                workers=4,alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(documents)\n",
    "for epoch in range(10):\n",
    "    print(\"epoch \"+str(epoch))\n",
    "    model.train(documents, total_examples=count, epochs=1)\n",
    "    model.save('noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model')\n" #files for model can be downloaded from here: https://yadi.sk/d/TjC0VYUH3Wi2JJ, https://yadi.sk/d/H3Hp4rA03Wi2K9,
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:21:24,399 : INFO : loading Doc2Vec object from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n",
      "2018-05-29 00:21:24,571 : INFO : loading wv recursively from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.wv.* with mmap=None\n",
      "2018-05-29 00:21:24,571 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-05-29 00:21:24,571 : INFO : loading docvecs recursively from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.* with mmap=None\n",
      "2018-05-29 00:21:24,587 : INFO : loading doctag_syn0 from noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "2018-05-29 00:21:24,649 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-29 00:21:24,665 : INFO : loaded noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec.load('noStopLemma_PV-DBOW_wrd-vec_1it_2win_6mincount_alpha25-25_sz80.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 00:21:28,743 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('пи', 0.7202205657958984),\n",
       " ('паралимпиада', 0.6802247166633606),\n",
       " ('олимпиада', 0.6634599566459656),\n",
       " ('финал', 0.6567267775535583),\n",
       " ('хоккеист', 0.647182822227478),\n",
       " ('пхенчхан', 0.6039129495620728),\n",
       " ('завоевать', 0.5854828953742981),\n",
       " ('немец', 0.5806310176849365),\n",
       " ('мороз', 0.576706051826477),\n",
       " ('керлингист', 0.5748294591903687)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try some words to check vector synonyms\n",
    "model.most_similar('ои')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('новак', 0.5740567445755005),\n",
       " ('медь', 0.5632855892181396),\n",
       " ('лукойл', 0.533349871635437),\n",
       " ('добыча', 0.5331281423568726),\n",
       " ('нефтепродукт', 0.525303304195404),\n",
       " ('wti', 0.5205585956573486),\n",
       " ('среднесуточный', 0.5045591592788696),\n",
       " ('энергоноситель', 0.5005838871002197),\n",
       " ('brent', 0.49924132227897644),\n",
       " ('сырьё', 0.4989580512046814)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('нефть')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('медведев', 0.7772114276885986),\n",
       " ('собянин', 0.6389020681381226),\n",
       " ('володин', 0.6102887392044067),\n",
       " ('матвиенко', 0.6037461757659912),\n",
       " ('песок', 0.6034808158874512),\n",
       " ('кириенко', 0.5740934610366821),\n",
       " ('дуда', 0.5674536228179932),\n",
       " ('топилина', 0.5671341419219971),\n",
       " ('голодец', 0.5665161609649658),\n",
       " ('хлопонин', 0.5633593201637268)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('путин')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
